# LLM Usage Log â€“ FacultyFinder Project

This document records the major prompts used with a Large Language Model (LLM) 
during the development of the FacultyFinder data engineering pipeline.

The LLM was used for design guidance, debugging assistance, and documentation support.

---

## 1. Project Architecture Design

**Prompt:**
> Design a data engineering pipeline to scrape faculty data from a college website, 
clean it, store it in a database, and serve it via an API for semantic search.

**Purpose:**
- To understand the end-to-end pipeline structure
- To identify appropriate tools for each stage

---

## 2. Scraping Strategy (Ingestion)

**Prompt:**
> How can I scrape faculty profile pages from a college directory using Scrapy, 
including handling pagination and following profile links?

**Purpose:**
- To design a scalable and reliable scraping approach
- To structure Scrapy spiders correctly

---

## 3. Handling Missing and Noisy Web Data

**Prompt:**
> What are common issues in scraped web data and how should missing or inconsistent 
fields be handled in a data engineering pipeline?

**Purpose:**
- To handle null values
- To ensure robustness against incomplete faculty profiles

---

## 4. Data Cleaning and Transformation Logic

**Prompt:**
> Write a clean_text function in Python to normalize scraped text, handle null values, 
and prepare text for downstream NLP tasks.

**Purpose:**
- To clean and normalize text data
- To standardize formatting across all records

---

## 5. NLP-Ready Dataset Design

**Prompt:**
> Why should multiple text fields (bio, specialization, teaching) be combined into a 
single field for semantic search and embeddings?

**Purpose:**
- To design the `bio_text` field
- To prepare data for semantic search in the Data Science phase

---

## 6. Database Schema Design

**Prompt:**
> Design a simple SQLite schema to store cleaned faculty data efficiently and avoid 
duplicate records.

**Purpose:**
- To create a persistent storage layer
- To ensure structured and queryable data

---

## 7. API Design for Data Serving

**Prompt:**
> How can I build a FastAPI service to expose stored faculty data as JSON for downstream 
data science and NLP tasks?

**Purpose:**
- To design REST endpoints (`/all`, `/faculty/{id}`)
- To implement the hand-off layer to Data Science

---

## 8. Project Documentation and README Structure

**Prompt:**
> What should be included in a README for a data engineering project to clearly explain 
the pipeline, schema, and execution steps?

**Purpose:**
- To improve documentation quality
- To ensure reproducibility and clarity

---

## Notes
- The LLM was used as a **development assistant**, not for data generation.
- All scraped data originates from publicly available faculty webpages.
- Final implementation decisions and code integration were performed manually.
